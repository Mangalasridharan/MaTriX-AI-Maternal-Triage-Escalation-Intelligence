"""
swarm_audit.py
==============
Automated Copilot / AI Swarm Architecture Review
------------------------------------------------
This script uses Copilot / an advanced LLM (e.g. GPT-4o) via API to review the
current LangGraph triage setup, looking for potential prompt or routing improvements
based on the drift score (discrepancies between AI and Nurse risk labels).
"""
import os, json, argparse
try:
    from openai import OpenAI
except ImportError:
    OpenAI = None

def main():
    parser = argparse.ArgumentParser()
    parser.add_argument("--drift_score", type=float, required=True)
    parser.add_argument("--output_path", type=str, required=True)
    args = parser.parse_args()

    # Define the core agents we want the Copilot to review
    agents = {
        "risk_agent.py": "Assess maternal risk from clinical vitals...",
        "router.py": "Evaluate risk_output + patient_data and decide whether to escalate...",
        "guideline_agent.py": "Produces a clinical management plan..."
    }

    print(f"ðŸ•µï¸â€â™‚ï¸ Running Copilot Swarm Audit (Drift: {args.drift_score})")

    # If API token is missing, mock a Copilot recommendation
    github_token = os.environ.get("GITHUB_TOKEN", "")
    if not github_token or not OpenAI:
        print("[audit] Defaulting to synthetic Copilot improvement for CI/CD demonstration.")
        
        # Example synthetic response: The Copilot suggests tightening BP bounds in the prompt
        improvements = {
            "improvements": [
                {
                    "target_file": "edge/app/agents/risk_agent.py",
                    "reasoning": f"A drift score of {args.drift_score} suggests the LLM is slightly under-triaging. We should adjust the system prompt to explicitly flag BP >= 140/90 as 'high' even without immediate symptoms.",
                    "search_string": "- high: Significant risk requiring urgent escalation. BP >= 140/90 + proteinuria or symptoms",
                    "replacement_string": "- high: Significant risk requiring urgent escalation. ANY BP >= 140/90, even isolated, warrants high risk monitoring."
                }
            ]
        }
    else:
        # Real Copilot Prompting Workflow using GitHub Models & OpenAI SDK
        client = OpenAI(
            base_url="https://models.inference.ai.azure.com",
            api_key=github_token
        )
        
        prompt = (
            f"You are the Copilot architect for MaTriX-AI, a maternal triage system.\n"
            f"The system recently experienced a label drift score of {args.drift_score}, meaning the "
            "AI and human nurses disagreed on risk severity.\n\n"
            "Review our current agent prompts and reasoning. Recommend specific search/replace edits "
            "to tighten the clinical guardrails in the Python source code. Output strict JSON format:\n"
            '{"improvements": [{"target_file": "path", "search_string": "old", "replacement_string": "new", "reasoning": "why"}]}'
        )
        
        response = client.chat.completions.create(
            model="gpt-4o",
            response_format={ "type": "json_object" },
            messages=[
                {"role": "system", "content": prompt},
                {"role": "user", "content": f"Review {list(agents.keys())}"}
            ]
        )
        improvements = json.loads(response.choices[0].message.content)

    # Save to JSON for the next script to apply
    with open(args.output_path, "w") as f:
        json.dump(improvements, f, indent=2)

    print(f"âœ… Audit complete. Found {len(improvements.get('improvements', []))} improvements.")

if __name__ == "__main__":
    main()
